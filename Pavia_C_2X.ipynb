{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ad8a51-08ab-4b6c-9172-abba95171456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:16:50.375329: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-21 16:16:50.389935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740147410.406323  199147 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740147410.411383  199147 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-21 16:16:50.429482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from scipy.io import loadmat \n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, UpSampling2D, Input, Conv2DTranspose, DepthwiseConv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5dfb62-359b-4a66-9e61-b2b02dfaf49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded .mat file: dict_keys(['__header__', '__version__', '__globals__', 'pavia'])\n",
      "Hyperspectral image shape: (1096, 715, 102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740147414.253269  199147 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hr shape: (313, 144, 144, 8)\n",
      "X_validation_hr shape: (44, 144, 144, 8)\n",
      "X_test_hr shape: (91, 144, 144, 8)\n",
      "X_train_lr shape: (313, 72, 72, 8)\n",
      "X_validation_lr shape: (44, 72, 72, 8)\n",
      "X_test_lr shape: (91, 72, 72, 8)\n"
     ]
    }
   ],
   "source": [
    "###### Set random seeds for reproducibility\n",
    "\n",
    "# Set all seeds for reproducibility\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Ensure TensorFlow uses deterministic operations\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load the Pavia dataset\n",
    "try:\n",
    "    data = loadmat(\"Pavia.mat\")  # Ensure that the file path is correct\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading .mat file: {e}\")\n",
    "\n",
    "# Access the hyperspectral image using the correct key 'pavia'\n",
    "print(\"Keys in loaded .mat file:\", data.keys())\n",
    "if 'pavia' in data:\n",
    "    hyperspectral_image = data['pavia']\n",
    "else:\n",
    "    raise KeyError(\"'pavia' not found in the .mat file.\")\n",
    "\n",
    "# Check the shape of the hyperspectral image\n",
    "print(\"Hyperspectral image shape:\", hyperspectral_image.shape)\n",
    "\n",
    "# Convert to float32 for TensorFlow operations\n",
    "hyperspectral_image = hyperspectral_image.astype(np.float32)\n",
    "\n",
    "# Load the hyperspectral data using the spectral library\n",
    "data = hyperspectral_image  # Use the loaded hyperspectral image directly\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 2  # Factor to downscale patches\n",
    "nodata_value = -1  # Value that indicates \"no data\"\n",
    "group_size = 8 # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                        [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                        method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(hyperspectral_image, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fd0577-a403-4488-875c-c811c0378a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Residual_CNN_SR_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Residual_CNN_SR_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">294,976</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">294,976</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,616</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m8\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m8\u001b[0m) │         \u001b[38;5;34m72\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m8\u001b[0m) │         \u001b[38;5;34m32\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m8\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m288\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m288\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m1,056\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m288\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m4,160\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m576\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │     \u001b[38;5;34m16,512\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m1,152\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │     \u001b[38;5;34m33,024\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │     \u001b[38;5;34m33,024\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │     \u001b[38;5;34m65,792\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m2,304\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │    \u001b[38;5;34m131,584\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │    \u001b[38;5;34m131,584\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │    \u001b[38;5;34m262,656\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │    \u001b[38;5;34m294,976\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │    \u001b[38;5;34m294,976\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │      \u001b[38;5;34m4,616\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,449,872</span> (16.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,449,872\u001b[0m (16.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,446,656</span> (16.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,446,656\u001b[0m (16.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,216</span> (12.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,216\u001b[0m (12.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 4449872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Convolution Block with Optional Residual Connection and Depthwise Separable Convolution\n",
    "# -----------------------------\n",
    "def conv_block(x, filters, kernel_size=(3, 3), use_residual=False, use_depthwise=False, l2_reg=1e-4):\n",
    "    shortcut = x  # Save the input as a shortcut\n",
    "\n",
    "    if use_depthwise:\n",
    "        x = DepthwiseConv2D(kernel_size, padding='same', use_bias=False, depthwise_regularizer=l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "    else:\n",
    "        x = Conv2D(filters, kernel_size, padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    if use_residual:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(l2_reg))(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "    \n",
    "    return x\n",
    "\n",
    "# -----------------------------\n",
    "# Dilated Convolution Fusion Block\n",
    "# -----------------------------\n",
    "def dilated_convolution_fusion_block(x, filters, l2_reg=1e-4):\n",
    "    spatial_branch = Conv2D(filters, (3, 3), dilation_rate=2, padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    spectral_branch = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    \n",
    "    x = Add()([spatial_branch, spectral_branch])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Upsampling Block with Optional Residual Connection\n",
    "# -----------------------------\n",
    "def upsample_block(x, filters, scale=2, use_residual=False, use_depthwise=False, use_transpose=False):\n",
    "    if not use_transpose:\n",
    "        shortcut = UpSampling2D(size=(scale, scale), interpolation='bilinear')(x)\n",
    "        shortcut = Conv2D(filters, (3, 3), padding='same')(shortcut)\n",
    "        \n",
    "        x = UpSampling2D(size=(scale, scale), interpolation='bilinear')(x)\n",
    "        if use_depthwise:\n",
    "            x = DepthwiseConv2D((3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "        else:\n",
    "            x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    else:\n",
    "        shortcut = Conv2DTranspose(filters, (3, 3), strides=scale, padding='same')(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        shortcut = Activation('relu')(shortcut)\n",
    "        \n",
    "        x = Conv2DTranspose(filters, (3, 3), strides=scale, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    if use_residual:\n",
    "        x = Add()([x, shortcut])\n",
    "    \n",
    "    return x\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss Functions\n",
    "# -----------------------------\n",
    "def custom_loss_with_l2(y_true, y_pred, model):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    l2_loss_val = sum(K.sum(K.square(w)) for w in model.trainable_weights)\n",
    "    l2_penalty = 1e-4 * l2_loss_val\n",
    "    return mse_loss + l2_penalty\n",
    "\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    grad_true_x, grad_true_y = tf.image.image_gradients(y_true)\n",
    "    grad_pred_x, grad_pred_y = tf.image.image_gradients(y_pred)\n",
    "    \n",
    "    spatial_loss = K.mean(K.square(grad_true_x - grad_pred_x) + K.square(grad_true_y - grad_pred_y))\n",
    "    \n",
    "    grad_true_spectral = tf.gradients(tf.reduce_mean(y_true, axis=[1, 2]), y_true)[0]\n",
    "    grad_pred_spectral = tf.gradients(tf.reduce_mean(y_pred, axis=[1, 2]), y_pred)[0]\n",
    "    \n",
    "    spectral_loss = K.mean(K.square(grad_true_spectral - grad_pred_spectral))\n",
    "    \n",
    "    return spatial_loss + spectral_loss\n",
    "\n",
    "def combined_loss(y_true, y_pred, model):\n",
    "    return custom_loss_with_l2(y_true, y_pred, model) + spatial_spectral_gradient_loss(y_true, y_pred)\n",
    "\n",
    "# -----------------------------\n",
    "# Build the Residual CNN Super-Resolution Model\n",
    "# -----------------------------\n",
    "def build_residual_cnn_sr_model(input_shape, use_depthwise=False, use_transpose=False, l2_reg=1e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = conv_block(inputs, filters=32, use_residual=True, use_depthwise=use_depthwise, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=32, l2_reg=l2_reg)\n",
    "    \n",
    "    x = conv_block(x, filters=64, use_residual=True, use_depthwise=use_depthwise, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=64, l2_reg=l2_reg)\n",
    "    \n",
    "    x = conv_block(x, filters=128, use_residual=True, use_depthwise=use_depthwise, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=128, l2_reg=l2_reg)\n",
    "    \n",
    "    x = conv_block(x, filters=256, use_residual=True, use_depthwise=use_depthwise, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=256, l2_reg=l2_reg)\n",
    "    \n",
    "    x = conv_block(x, filters=512, use_residual=True, use_depthwise=use_depthwise, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=512, l2_reg=l2_reg)\n",
    "    \n",
    "    x = upsample_block(x, filters=64, scale=2, use_residual=True, use_depthwise=use_depthwise, use_transpose=use_transpose)\n",
    " #   x = upsample_block(x, filters=32, scale=2, use_residual=True, use_depthwise=use_depthwise, use_transpose=use_transpose)\n",
    "#    x = upsample_block(x, filters=16, scale=2, use_residual=True, use_depthwise=use_depthwise, use_transpose=use_transpose)\n",
    "    \n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x_out, name=\"Residual_CNN_SR_Model\")\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Define Input Shape and Build the Model\n",
    "# -----------------------------\n",
    "input_shape = (72, 72, 8)  \n",
    "residual_cnn_sr_model = build_residual_cnn_sr_model(input_shape, use_depthwise=True, use_transpose=True)\n",
    "\n",
    "# Compile with Combined Loss\n",
    "residual_cnn_sr_model.compile(optimizer='adam', loss=lambda y_true, y_pred: combined_loss(y_true, y_pred, residual_cnn_sr_model))\n",
    "\n",
    "# Print model summary\n",
    "residual_cnn_sr_model.summary()\n",
    "\n",
    "# Count total trainable parameters\n",
    "total_params = residual_cnn_sr_model.count_params()\n",
    "print(f\"Total Trainable Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18699405-420e-4c61-8b17-6ad09acb7731",
   "metadata": {},
   "source": [
    "## Model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca95983-da5a-47c7-97e6-77f52414e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:16:57.005722: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740147425.779738  199617 service.cc:148] XLA service 0x7f12040210d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740147425.780614  199617 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-02-21 16:17:06.196161: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1740147427.510220  199617 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-02-21 16:17:09.542029: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,128,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,38,38]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:09.542048: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:09.542051: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.114 = (f32[16,128,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,38,38]{3,2,1,0} %bitcast.9112, f32[128,128,3,3]{3,2,1,0} %bitcast.16534, f32[128]{0} %arg46.47), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_10_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:17:09.611899: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,38,38]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:09.611916: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:09.611920: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.118 = (f32[16,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,38,38]{3,2,1,0} %bitcast.9270, f32[256,256,3,3]{3,2,1,0} %bitcast.16548, f32[256]{0} %arg63.64), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_14_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:17:09.638016: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,38,38]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:09.638029: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:09.638032: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.122 = (f32[16,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,38,38]{3,2,1,0} %bitcast.9428, f32[512,512,3,3]{3,2,1,0} %bitcast.16560, f32[512]{0} %arg80.81), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_18_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:17:17.257339: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_9', 8 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1740147437.320579  199617 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2056028.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:17:29.428476: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_7', 8 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-02-21 16:17:30.741877: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,128,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,38,38]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:30.741894: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:30.741897: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.83 = (f32[16,128,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,38,38]{3,2,1,0} %bitcast.2068, f32[128,128,3,3]{3,2,1,0} %bitcast.3357, f32[128]{0} %arg46.47), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_10_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:17:30.749957: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,38,38]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:30.749969: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:30.749972: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.87 = (f32[16,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,38,38]{3,2,1,0} %bitcast.2182, f32[256,256,3,3]{3,2,1,0} %bitcast.3371, f32[256]{0} %arg63.64), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_14_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:17:30.763430: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,38,38]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:17:30.763441: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:17:30.763445: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.91 = (f32[16,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,38,38]{3,2,1,0} %bitcast.2296, f32[512,512,3,3]{3,2,1,0} %bitcast.3385, f32[512]{0} %arg80.81), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_18_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 198ms/step - loss: 2056420.8750 - val_loss: 605289.5625\n",
      "Epoch 2/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 1814615.2500 - val_loss: 485659.7188\n",
      "Epoch 3/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 1526914.0000 - val_loss: 445798.2812\n",
      "Epoch 4/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 1219562.8750 - val_loss: 1030635.7500\n",
      "Epoch 5/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 924161.2500 - val_loss: 720131.7500\n",
      "Epoch 6/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 674912.6875 - val_loss: 471444.5312\n",
      "Epoch 7/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 488133.1250 - val_loss: 261408.9844\n",
      "Epoch 8/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 367450.4688 - val_loss: 163606.6875\n",
      "Epoch 9/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 288463.1875 - val_loss: 147289.6250\n",
      "Epoch 10/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 242006.8438 - val_loss: 182397.4844\n",
      "Epoch 11/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 218856.2812 - val_loss: 148321.5469\n",
      "Epoch 12/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 202892.4531 - val_loss: 178133.2031\n",
      "Epoch 13/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 194890.1406 - val_loss: 199917.4844\n",
      "Epoch 14/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 185089.9219 - val_loss: 165157.4531\n",
      "Epoch 15/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 176456.5000 - val_loss: 147921.7344\n",
      "Epoch 16/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 171799.3125 - val_loss: 179992.4219\n",
      "Epoch 17/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 169129.0156 - val_loss: 129554.5703\n",
      "Epoch 18/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 154145.0156 - val_loss: 128185.9688\n",
      "Epoch 19/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 137138.5156 - val_loss: 139502.7500\n",
      "Epoch 20/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 139773.1875 - val_loss: 130633.9062\n",
      "Epoch 21/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 133161.1562 - val_loss: 121040.6953\n",
      "Epoch 22/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 127288.2578 - val_loss: 122351.6953\n",
      "Epoch 23/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 122755.0000 - val_loss: 120328.8438\n",
      "Epoch 24/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 122215.6562 - val_loss: 133486.0156\n",
      "Epoch 25/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 126875.5547 - val_loss: 122370.2422\n",
      "Epoch 26/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 120147.7891 - val_loss: 126584.8672\n",
      "Epoch 27/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 118814.7266 - val_loss: 122650.7578\n",
      "Epoch 28/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 115856.9453 - val_loss: 142414.1875\n",
      "Epoch 29/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 117510.1641 - val_loss: 118642.7812\n",
      "Epoch 30/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 114904.6953 - val_loss: 119726.3438\n",
      "Epoch 31/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 112348.5469 - val_loss: 125466.3203\n",
      "Epoch 32/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 109398.0859 - val_loss: 117596.2422\n",
      "Epoch 33/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 108386.6016 - val_loss: 125909.7578\n",
      "Epoch 34/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 106197.4609 - val_loss: 125818.3203\n",
      "Epoch 35/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 108247.3828 - val_loss: 108688.9297\n",
      "Epoch 36/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 103502.6875 - val_loss: 107581.4922\n",
      "Epoch 37/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 100541.5234 - val_loss: 110101.3750\n",
      "Epoch 38/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 97621.2266 - val_loss: 120127.2188\n",
      "Epoch 39/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 95191.1641 - val_loss: 109467.3750\n",
      "Epoch 40/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 94074.0469 - val_loss: 105102.9922\n",
      "Epoch 41/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 93893.8828 - val_loss: 127477.3984\n",
      "Epoch 42/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 91748.7109 - val_loss: 118128.4453\n",
      "Epoch 43/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 91979.4375 - val_loss: 95778.2422\n",
      "Epoch 44/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 87832.1484 - val_loss: 105543.6016\n",
      "Epoch 45/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 87596.7344 - val_loss: 94886.0781\n",
      "Epoch 46/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 83782.8594 - val_loss: 104435.7812\n",
      "Epoch 47/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 87229.3750 - val_loss: 91026.4688\n",
      "Epoch 48/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 83614.5312 - val_loss: 92295.8203\n",
      "Epoch 49/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 81296.7891 - val_loss: 92595.8594\n",
      "Epoch 50/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 95010.5078 - val_loss: 89309.1953\n",
      "Epoch 51/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 77113.9922 - val_loss: 112728.3672\n",
      "Epoch 52/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 73268.5781 - val_loss: 83335.8984\n",
      "Epoch 53/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 69040.4141 - val_loss: 79770.9297\n",
      "Epoch 54/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 66315.4922 - val_loss: 82931.1094\n",
      "Epoch 55/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 63794.8984 - val_loss: 77612.7812\n",
      "Epoch 56/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 61694.1523 - val_loss: 77912.6719\n",
      "Epoch 57/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 60081.5078 - val_loss: 76897.0312\n",
      "Epoch 58/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 59353.1055 - val_loss: 87017.0547\n",
      "Epoch 59/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 59325.6094 - val_loss: 76916.4141\n",
      "Epoch 60/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 60579.3750 - val_loss: 110971.3047\n",
      "Epoch 61/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 68795.2031 - val_loss: 120178.6172\n",
      "Epoch 62/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 61420.5000 - val_loss: 89507.8438\n",
      "Epoch 63/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 61860.4219 - val_loss: 85271.2109\n",
      "Epoch 64/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 59812.4062 - val_loss: 78406.1719\n",
      "Epoch 65/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 55390.8125 - val_loss: 68783.1641\n",
      "Epoch 66/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 53708.8203 - val_loss: 66460.8438\n",
      "Epoch 67/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 50518.0352 - val_loss: 68722.4766\n",
      "Epoch 68/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 49639.4883 - val_loss: 68632.7188\n",
      "Epoch 69/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 48135.6328 - val_loss: 63699.6602\n",
      "Epoch 70/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 46806.8828 - val_loss: 63931.3750\n",
      "Epoch 71/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 46157.6523 - val_loss: 67864.8438\n",
      "Epoch 72/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 44622.6328 - val_loss: 65048.3789\n",
      "Epoch 73/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 44392.7031 - val_loss: 74439.8359\n",
      "Epoch 74/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 45564.1406 - val_loss: 72329.1719\n",
      "Epoch 75/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 46687.4805 - val_loss: 66996.5391\n",
      "Epoch 76/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 48104.7969 - val_loss: 77744.9609\n",
      "Epoch 77/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 52050.0039 - val_loss: 69480.6562\n",
      "Epoch 78/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 52226.3359 - val_loss: 105180.2734\n",
      "Epoch 79/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 49036.3711 - val_loss: 65489.5586\n",
      "Epoch 80/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 43340.2734 - val_loss: 58719.7227\n",
      "Epoch 81/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 39620.6875 - val_loss: 57161.0000\n",
      "Epoch 82/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 38514.6406 - val_loss: 57412.9961\n",
      "Epoch 83/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 37634.3594 - val_loss: 54294.6602\n",
      "Epoch 84/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 36639.7383 - val_loss: 54229.8125\n",
      "Epoch 85/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 35666.2930 - val_loss: 55942.2969\n",
      "Epoch 86/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 35174.8516 - val_loss: 60824.5273\n",
      "Epoch 87/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 34284.9102 - val_loss: 55536.8125\n",
      "Epoch 88/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 33442.1797 - val_loss: 65302.8398\n",
      "Epoch 89/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 32991.3203 - val_loss: 57464.2617\n",
      "Epoch 90/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 32433.6992 - val_loss: 57739.8633\n",
      "Epoch 91/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 32498.9102 - val_loss: 59556.0586\n",
      "Epoch 92/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 33795.8750 - val_loss: 58722.6523\n",
      "Epoch 93/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 37216.5625 - val_loss: 52433.6914\n",
      "Epoch 94/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 35355.4688 - val_loss: 62632.6992\n",
      "Epoch 95/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 34167.2891 - val_loss: 57954.7500\n",
      "Epoch 96/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 34132.2656 - val_loss: 49024.8125\n",
      "Epoch 97/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 32330.0996 - val_loss: 50645.7227\n",
      "Epoch 98/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 29978.7578 - val_loss: 57649.2031\n",
      "Epoch 99/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 30584.5762 - val_loss: 47770.4258\n",
      "Epoch 100/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 30451.4980 - val_loss: 60842.4609\n",
      "Epoch 101/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 32085.3105 - val_loss: 48947.1914\n",
      "Epoch 102/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 29206.1758 - val_loss: 65663.5469\n",
      "Epoch 103/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 28578.9238 - val_loss: 52368.8125\n",
      "Epoch 104/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 28705.8691 - val_loss: 62820.4766\n",
      "Epoch 105/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 27878.3652 - val_loss: 51181.7773\n",
      "Epoch 106/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 26267.0117 - val_loss: 47514.9102\n",
      "Epoch 107/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25909.7285 - val_loss: 55492.6875\n",
      "Epoch 108/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 26090.4863 - val_loss: 53385.0859\n",
      "Epoch 109/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25216.4375 - val_loss: 45711.6445\n",
      "Epoch 110/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25748.1660 - val_loss: 44469.5078\n",
      "Epoch 111/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25253.7031 - val_loss: 52439.8008\n",
      "Epoch 112/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 26924.4980 - val_loss: 48957.0586\n",
      "Epoch 113/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 30713.8574 - val_loss: 84500.4297\n",
      "Epoch 114/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 60170.8828 - val_loss: 112168.3047\n",
      "Epoch 115/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 38428.6992 - val_loss: 65039.3633\n",
      "Epoch 116/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 30819.3457 - val_loss: 46382.4141\n",
      "Epoch 117/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 27322.5273 - val_loss: 44980.5195\n",
      "Epoch 118/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25848.4199 - val_loss: 49400.5664\n",
      "Epoch 119/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25045.8047 - val_loss: 47613.0469\n",
      "Epoch 120/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23866.1758 - val_loss: 46546.8164\n",
      "Epoch 121/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23167.0508 - val_loss: 42844.3125\n",
      "Epoch 122/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22781.8184 - val_loss: 42938.2773\n",
      "Epoch 123/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22563.7090 - val_loss: 42298.2773\n",
      "Epoch 124/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22450.0293 - val_loss: 43608.5000\n",
      "Epoch 125/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22384.2949 - val_loss: 42451.0664\n",
      "Epoch 126/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22476.5176 - val_loss: 44358.2148\n",
      "Epoch 127/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22528.0918 - val_loss: 43029.0586\n",
      "Epoch 128/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22340.4258 - val_loss: 42101.9531\n",
      "Epoch 129/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22395.3691 - val_loss: 42384.2266\n",
      "Epoch 130/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22276.7031 - val_loss: 39741.7070\n",
      "Epoch 131/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22334.1133 - val_loss: 43450.8359\n",
      "Epoch 132/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22776.9336 - val_loss: 41427.7891\n",
      "Epoch 133/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23953.8691 - val_loss: 40682.5781\n",
      "Epoch 134/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 24298.1172 - val_loss: 73644.1953\n",
      "Epoch 135/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 45270.4023 - val_loss: 159193.6719\n",
      "Epoch 136/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 57338.8359 - val_loss: 112235.7734\n",
      "Epoch 137/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 33853.5977 - val_loss: 43471.9844\n",
      "Epoch 138/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 28361.8125 - val_loss: 44011.3008\n",
      "Epoch 139/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 27054.5781 - val_loss: 50378.0352\n",
      "Epoch 140/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25997.5000 - val_loss: 40230.3633\n",
      "Epoch 141/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22673.2773 - val_loss: 39831.5078\n",
      "Epoch 142/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21342.4492 - val_loss: 41716.7891\n",
      "Epoch 143/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 20621.3965 - val_loss: 42760.0508\n",
      "Epoch 144/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20223.6641 - val_loss: 42270.3203\n",
      "Epoch 145/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19923.1719 - val_loss: 42105.8164\n",
      "Epoch 146/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19666.0098 - val_loss: 41920.6758\n",
      "Epoch 147/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19405.5312 - val_loss: 41856.2578\n",
      "Epoch 148/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19206.7656 - val_loss: 41442.4883\n",
      "Epoch 149/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18988.6953 - val_loss: 41120.1914\n",
      "Epoch 150/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18823.9375 - val_loss: 41774.8164\n",
      "Epoch 151/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18706.3652 - val_loss: 40686.8242\n",
      "Epoch 152/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18580.5430 - val_loss: 40451.9258\n",
      "Epoch 153/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18451.2383 - val_loss: 38988.0156\n",
      "Epoch 154/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18312.8887 - val_loss: 39806.8672\n",
      "Epoch 155/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18248.4062 - val_loss: 38655.6406\n",
      "Epoch 156/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18460.9766 - val_loss: 42623.8594\n",
      "Epoch 157/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21981.6895 - val_loss: 39058.7656\n",
      "Epoch 158/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23972.1621 - val_loss: 51926.8594\n",
      "Epoch 159/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 30247.6855 - val_loss: 41037.0781\n",
      "Epoch 160/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 26530.4805 - val_loss: 87766.6875\n",
      "Epoch 161/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 24194.0117 - val_loss: 39385.6445\n",
      "Epoch 162/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 24017.4629 - val_loss: 38034.9648\n",
      "Epoch 163/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23343.8164 - val_loss: 38480.2578\n",
      "Epoch 164/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23456.8438 - val_loss: 36892.5742\n",
      "Epoch 165/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20473.0586 - val_loss: 36898.5273\n",
      "Epoch 166/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19053.5977 - val_loss: 35545.9961\n",
      "Epoch 167/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18001.6621 - val_loss: 39000.1562\n",
      "Epoch 168/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17564.4766 - val_loss: 39606.8984\n",
      "Epoch 169/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17339.9961 - val_loss: 40353.9023\n",
      "Epoch 170/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17082.4355 - val_loss: 42297.6211\n",
      "Epoch 171/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17052.5879 - val_loss: 40636.2461\n",
      "Epoch 172/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17083.3145 - val_loss: 40581.8477\n",
      "Epoch 173/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17082.3320 - val_loss: 39002.8477\n",
      "Epoch 174/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17102.1016 - val_loss: 37256.1758\n",
      "Epoch 175/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17615.5352 - val_loss: 36431.0742\n",
      "Epoch 176/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18341.6211 - val_loss: 40429.3906\n",
      "Epoch 177/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19162.0859 - val_loss: 43180.5781\n",
      "Epoch 178/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19802.8594 - val_loss: 41372.1602\n",
      "Epoch 179/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22419.0293 - val_loss: 50478.3984\n",
      "Epoch 180/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21205.3789 - val_loss: 37179.6289\n",
      "Epoch 181/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20037.2520 - val_loss: 42607.2852\n",
      "Epoch 182/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19967.1523 - val_loss: 34448.0117\n",
      "Epoch 183/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21630.7598 - val_loss: 35738.1836\n",
      "Epoch 184/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20772.4766 - val_loss: 39554.7578\n",
      "Epoch 185/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20205.6660 - val_loss: 61195.4844\n",
      "Epoch 186/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22366.9746 - val_loss: 38117.8516\n",
      "Epoch 187/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20785.9453 - val_loss: 40985.3906\n",
      "Epoch 188/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20009.1504 - val_loss: 38132.9492\n",
      "Epoch 189/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19213.7949 - val_loss: 38540.3633\n",
      "Epoch 190/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18023.8691 - val_loss: 43627.3203\n",
      "Epoch 191/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17506.3262 - val_loss: 36670.7969\n",
      "Epoch 192/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17083.9961 - val_loss: 37894.5586\n",
      "Epoch 193/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17342.0020 - val_loss: 38195.4961\n",
      "Epoch 194/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17088.8613 - val_loss: 36154.1602\n",
      "Epoch 195/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16937.2969 - val_loss: 39338.6719\n",
      "Epoch 196/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16844.7871 - val_loss: 40654.6289\n",
      "Epoch 197/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16902.9941 - val_loss: 38170.3711\n",
      "Epoch 198/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16962.7090 - val_loss: 40938.3789\n",
      "Epoch 199/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16956.7695 - val_loss: 35908.4805\n",
      "Epoch 200/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17222.2207 - val_loss: 35557.3555\n",
      "Epoch 201/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17520.2520 - val_loss: 40010.1367\n",
      "Epoch 202/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19262.1484 - val_loss: 39149.2656\n",
      "Epoch 203/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20928.9512 - val_loss: 45891.0859\n",
      "Epoch 204/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 46965.0703 - val_loss: 157901.5156\n",
      "Epoch 205/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 77902.1406 - val_loss: 476175.5312\n",
      "Epoch 206/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 37126.3398 - val_loss: 84357.0703\n",
      "Epoch 207/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 29859.5391 - val_loss: 42196.7461\n",
      "Epoch 208/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 24610.8828 - val_loss: 43192.0352\n",
      "Epoch 209/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21783.6641 - val_loss: 45609.0625\n",
      "Epoch 210/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19777.0391 - val_loss: 43485.7969\n",
      "Epoch 211/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19049.6328 - val_loss: 41295.2305\n",
      "Epoch 212/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18065.4941 - val_loss: 39379.3984\n",
      "Epoch 213/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17421.1074 - val_loss: 39381.0273\n",
      "Epoch 214/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16984.4160 - val_loss: 38755.4648\n",
      "Epoch 215/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16651.5059 - val_loss: 38532.7500\n",
      "Epoch 216/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16385.7891 - val_loss: 37289.9102\n",
      "Epoch 217/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16171.4824 - val_loss: 37333.3516\n",
      "Epoch 218/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15983.0029 - val_loss: 35444.5664\n",
      "Epoch 219/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15786.8086 - val_loss: 35667.3711\n",
      "Epoch 220/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15691.3057 - val_loss: 34130.3398\n",
      "Epoch 221/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15568.8018 - val_loss: 34190.8398\n",
      "Epoch 222/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15666.0840 - val_loss: 33736.0234\n",
      "Epoch 223/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15606.4307 - val_loss: 32154.5625\n",
      "Epoch 224/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15559.4893 - val_loss: 35365.9727\n",
      "Epoch 225/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15566.5859 - val_loss: 33833.2539\n",
      "Epoch 226/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15817.9795 - val_loss: 31782.1855\n",
      "Epoch 227/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15898.6973 - val_loss: 34771.6211\n",
      "Epoch 228/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16038.0283 - val_loss: 32873.1523\n",
      "Epoch 229/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16183.8428 - val_loss: 35781.1406\n",
      "Epoch 230/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16534.6426 - val_loss: 32972.5664\n",
      "Epoch 231/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18293.2969 - val_loss: 35680.0117\n",
      "Epoch 232/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19546.5664 - val_loss: 43204.3750\n",
      "Epoch 233/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19917.5723 - val_loss: 34023.9609\n",
      "Epoch 234/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17177.4961 - val_loss: 37362.7930\n",
      "Epoch 235/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16359.2051 - val_loss: 36898.3711\n",
      "Epoch 236/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15681.4102 - val_loss: 36600.5586\n",
      "Epoch 237/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15506.0977 - val_loss: 34607.1133\n",
      "Epoch 238/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15434.6553 - val_loss: 34169.2148\n",
      "Epoch 239/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15325.2646 - val_loss: 37114.9375\n",
      "Epoch 240/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15209.7324 - val_loss: 38249.5156\n",
      "Epoch 241/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15259.5723 - val_loss: 32897.3789\n",
      "Epoch 242/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15749.5283 - val_loss: 33412.1719\n",
      "Epoch 243/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16086.5859 - val_loss: 35531.0977\n",
      "Epoch 244/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17378.0859 - val_loss: 37176.9648\n",
      "Epoch 245/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17574.0938 - val_loss: 48536.4883\n",
      "Epoch 246/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18139.5020 - val_loss: 37680.1328\n",
      "Epoch 247/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19801.5332 - val_loss: 46372.8828\n",
      "Epoch 248/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 22293.3926 - val_loss: 34686.5547\n",
      "Epoch 249/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18531.4551 - val_loss: 32666.0059\n",
      "Epoch 250/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19383.7812 - val_loss: 39675.6992\n",
      "Epoch 251/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 21257.5508 - val_loss: 67277.1016\n",
      "Epoch 252/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18346.5840 - val_loss: 36385.1094\n",
      "Epoch 253/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17809.3281 - val_loss: 33100.9883\n",
      "Epoch 254/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16377.4736 - val_loss: 31163.5684\n",
      "Epoch 255/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15398.2988 - val_loss: 32041.4316\n",
      "Epoch 256/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14950.7461 - val_loss: 33643.1641\n",
      "Epoch 257/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14439.2373 - val_loss: 34434.3203\n",
      "Epoch 258/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14250.8076 - val_loss: 34442.9141\n",
      "Epoch 259/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14084.2900 - val_loss: 35412.2188\n",
      "Epoch 260/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13995.2920 - val_loss: 35901.3086\n",
      "Epoch 261/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13936.0391 - val_loss: 36009.6094\n",
      "Epoch 262/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13914.8369 - val_loss: 36376.8086\n",
      "Epoch 263/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13950.0459 - val_loss: 35899.1914\n",
      "Epoch 264/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14028.7275 - val_loss: 36510.9961\n",
      "Epoch 265/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14061.5234 - val_loss: 35086.0859\n",
      "Epoch 266/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14091.3643 - val_loss: 32777.0977\n",
      "Epoch 267/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14194.3486 - val_loss: 32904.7070\n",
      "Epoch 268/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14385.3965 - val_loss: 33075.7773\n",
      "Epoch 269/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14564.9688 - val_loss: 31940.5117\n",
      "Epoch 270/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15194.5664 - val_loss: 34779.0156\n",
      "Epoch 271/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15881.4131 - val_loss: 37785.3320\n",
      "Epoch 272/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18609.9648 - val_loss: 47629.3555\n",
      "Epoch 273/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20397.6875 - val_loss: 36805.1914\n",
      "Epoch 274/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20391.2676 - val_loss: 166991.8594\n",
      "Epoch 275/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 56138.7422 - val_loss: 53716.1016\n",
      "Epoch 276/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 35045.6758 - val_loss: 44637.3164\n",
      "Epoch 277/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 42011.2812 - val_loss: 72139.9922\n",
      "Epoch 278/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 55527.0781 - val_loss: 70355.6953\n",
      "Epoch 279/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 29646.8086 - val_loss: 39991.4883\n",
      "Epoch 280/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 25424.2090 - val_loss: 35647.5781\n",
      "Epoch 281/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 23207.4824 - val_loss: 34138.5469\n",
      "Epoch 282/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 20870.7773 - val_loss: 33627.8828\n",
      "Epoch 283/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 19250.4609 - val_loss: 33552.3438\n",
      "Epoch 284/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 18225.0156 - val_loss: 33700.4805\n",
      "Epoch 285/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 17508.2988 - val_loss: 33914.3281\n",
      "Epoch 286/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16950.3613 - val_loss: 34100.5352\n",
      "Epoch 287/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16457.8320 - val_loss: 33776.6328\n",
      "Epoch 288/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 16048.5566 - val_loss: 33850.8438\n",
      "Epoch 289/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15721.4385 - val_loss: 33529.2227\n",
      "Epoch 290/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15425.6729 - val_loss: 33192.6680\n",
      "Epoch 291/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 15159.6670 - val_loss: 32995.0352\n",
      "Epoch 292/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14928.6416 - val_loss: 32635.7949\n",
      "Epoch 293/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14730.9893 - val_loss: 32490.8867\n",
      "Epoch 294/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14524.7510 - val_loss: 32442.3008\n",
      "Epoch 295/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14350.0713 - val_loss: 32424.8691\n",
      "Epoch 296/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14186.5430 - val_loss: 32236.2637\n",
      "Epoch 297/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 14043.4082 - val_loss: 32171.4863\n",
      "Epoch 298/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13908.1543 - val_loss: 32404.6641\n",
      "Epoch 299/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13789.5850 - val_loss: 32320.7051\n",
      "Epoch 300/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13678.0898 - val_loss: 32330.7695\n",
      "Epoch 301/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13596.0762 - val_loss: 31200.4238\n",
      "Epoch 302/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13516.7324 - val_loss: 31848.9355\n",
      "Epoch 303/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13438.6865 - val_loss: 32784.4844\n",
      "Epoch 304/1000\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 13361.7266 - val_loss: 31322.1797\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = residual_cnn_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=1000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53445adc-bc24-4bcc-bcf3-e9534319ae2e",
   "metadata": {},
   "source": [
    "## Report all the metrices such as PSNR , SSIM, SAM, CC, ERGAS, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee55409-f545-4efd-89c6-8531a950faf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:43:33.473623: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 16:43:36.016313: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[12,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,256,38,38]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:43:36.016329: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:43:36.016333: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.87 = (f32[12,256,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,256,38,38]{3,2,1,0} %bitcast.1326, f32[256,256,3,3]{3,2,1,0} %bitcast.1679, f32[256]{0} %arg62.63), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_14_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-02-21 16:43:36.035999: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[12,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,512,38,38]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-02-21 16:43:36.036014: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:874] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2025-02-21 16:43:36.036017: W external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:877] Conv: %cudnn-conv-bias-activation.91 = (f32[12,512,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,512,38,38]{3,2,1,0} %bitcast.1440, f32[512,512,3,3]{3,2,1,0} %bitcast.1691, f32[512]{0} %arg79.80), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Residual_CNN_SR_Model_1/conv2d_18_1/convolution\" source_file=\"/usr/local/lib64/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step\n",
      "Average PSNR on the test set: 39.50195365227186\n",
      "Average SSIM on the test set: 0.96571994\n",
      "Average SAM on the test set (in degrees): 3.418970912039513\n",
      "Average Correlation Coefficient on the test set: 0.9904555296131157\n",
      "Average ERGAS on the test set: 3.998514506376669\n",
      "Average RMSE: 0.011225838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def psnr(y_true, y_pred, max_pixel=None):\n",
    "    \"\"\"\n",
    "    Compute PSNR for each spectral band separately and return the average.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth image, shape (H, W, B)\n",
    "        y_pred: Super-resolved image, shape (H, W, B)\n",
    "        max_pixel: Maximum pixel value (None = use actual max from y_true)\n",
    "    \n",
    "    Returns:\n",
    "        Average PSNR across all bands\n",
    "    \"\"\"\n",
    "    if max_pixel is None:\n",
    "        max_pixel = np.max(y_true)  # Auto-detect max value if not provided\n",
    "\n",
    "    B = y_true.shape[-1]  # Number of spectral bands\n",
    "    psnr_values = []\n",
    "    \n",
    "    for i in range(B):  # Loop over bands\n",
    "        mse = np.mean((y_true[..., i] - y_pred[..., i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr_values.append(float('inf'))  # Perfect reconstruction\n",
    "        else:\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "            psnr_values.append(psnr)\n",
    "    \n",
    "    return np.mean(psnr_values)  # Average across bands\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images =  residual_cnn_sr_model.predict(X_test_lr, batch_size=4)\n",
    "\n",
    "downscale_factor = 2 # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bf59f-2abf-42d2-9769-7fe6febfb0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
