# Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Convolutional Network


Deep neural networks have demonstrated highly competitive performance in super-resolution (SR) for natural images by learning mappings from low-resolution (LR) to high-resolution (HR) images. However, hyperspectral SR remains an ill-posed problem due to its high spectral dimensionality. Existing methods often rely on large models with a high number of parameters or require the fusion of panchromatic or RGB images, both of which are often impractical in real-world scenarios. Inspired by the MobileNet architecture, we introduce a lightweight depthwise separable convolutional network to address aforementioned challenges. Specifically, our proposed model leverages multiple depthwise separable convolutions similar to the MobileNet architecture; however, we employ a dilated convolution fusion block with each depthwise separable convolutional block to make the model more flexible for the extraction of both spatial and spectral features. In addition, we propose a custom loss function that combines mean squared error (MSE), an L2 regularization-based constraint, and a spatial-spectral gradient loss to ensure high-fidelity reconstruction. The proposed architecture achieves state-of-the-art performance on two publicly available hyperspectral datasets, making it well-suited for hyperspectral image super-resolution tasks.
